{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","anaconda-cloud":{},"colab":{"name":"CV - ICG.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjFgAFSS4jNL","executionInfo":{"status":"ok","timestamp":1637745721873,"user_tz":-330,"elapsed":11553,"user":{"displayName":"17PD35 - SRUTHI S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13321935041235545449"}},"outputId":"c803ba02-12aa-4a1a-e34e-01882fb921ac"},"source":["!pip install scipy==1.1.0\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scipy==1.1.0\n","  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n","\u001b[K     |████████████████████████████████| 31.2 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n","Installing collected packages: scipy\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n","plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n","jax 0.2.25 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed scipy-1.1.0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KiAWJzcv5Doc","executionInfo":{"status":"ok","timestamp":1637745813311,"user_tz":-330,"elapsed":25626,"user":{"displayName":"17PD35 - SRUTHI S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13321935041235545449"}},"outputId":"8d3632f5-9f5d-4c98-95c1-32b340df4893"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"_HVGU_OLh3EG"},"source":["!cp /content/drive/MyDrive/CV/modules/models.py /content/\n","!cp /content/drive/MyDrive/CV/modules/utils.py /content/\n","!cp /content/drive/MyDrive/CV/modules/eval.py /content/\n","!cp /content/drive/MyDrive/CV/modules/datasets.py /content/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-6SojC9TQYws","executionInfo":{"status":"ok","timestamp":1636953619190,"user_tz":-330,"elapsed":3597,"user":{"displayName":"17PD35 - SRUTHI S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13321935041235545449"}},"outputId":"8032b5f7-af3a-4e55-99a7-e036ae5e0149"},"source":["!pip install torch"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"]}]},{"cell_type":"code","metadata":{"id":"WwTER4gGLJMs"},"source":["import time\n","import torch.backends.cudnn as cudnn\n","import torch.optim\n","from torch.utils.data  import *\n","import torchvision.transforms as transforms\n","from torch import nn\n","from torch.nn.utils.rnn import pack_padded_sequence\n","import torchvision\n","from models import CNN, LSTMwithAttention\n","from utils import *\n","from nltk.translate.bleu_score import corpus_bleu\n","import h5py\n","import json\n","import os\n","import numpy as np\n","from scipy.misc import imread, imresize\n","from tqdm import tqdm\n","from collections import Counter\n","from random import seed, choice, sample\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h2egyDKJM47v"},"source":["\n","def clip_gradient(optimizer, grad_clip):\n","    for group in optimizer.param_groups:\n","        for param in group['params']:\n","            if param.grad is not None:\n","                param.grad.data.clamp_(-grad_clip, grad_clip)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qU5P8wQLRs_x"},"source":["\n","\n","\n","class AvgMtrt):\n","\n","    def __init__(self):\n","        self.resets()\n","\n","    def reset(self):\n","        self.vals = 0\n","        self.avgs= 0\n","        self.sums = 0\n","        self.counts = 0\n","\n","    def update(self, vals, num=1):\n","        self.vals = vals\n","        self.sums += vals * num\n","        self.counts += num\n","        self.avgs = self.sums / self.counts\n","\n","\n","def adjust_learning_rate(optim, s_factor):\n","    for param_group in optim.param_groups:\n","        param_group['lr'] = param_group['lr'] * s_factor\n","\n","\n","def accuracy(score, target, top_k):\n","    batch_size = target.size(0)\n","    _, ind = score.topk(top_k, 1, True, True)\n","    correct = ind.eq(target.view(-1, 1).expand_as(ind))\n","    correct_total = correct.view(-1).float().sum()  # 0D tensor\n","    return correct_total.item() * (100.0 / batch_size)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_6KF70bmQ0mN"},"source":["# Dataset"]},{"cell_type":"code","metadata":{"id":"llpyCilNQy6_"},"source":["class Captions_Dataset(Dataset):\n","\n","    def __init__(self, data_folder, data_name, splits, transforms=None):\n","        self.splitss = splits\n","\n","\n","        with open(os.path.join(data_folder, self.splits + '_cap_lenss_' + data_name + '.json'), 'r') as j:\n","            self.cap_lens = json.load(j)\n","\n","\n","        self.dataset_size = len(self.captions)\n","\n","\n","        self.h5py5py = h5py.File(os.path.join(data_folder, self.splits + '_IMAGES_' + data_name + '.hdf5'), 'r')\n","        self.imgs = self.h5py['images']\n","\n","        self.captions_per_image = self.h5py.attrs['captions_per_image']\n","\n","        with open(os.path.join(data_folder, self.splits + '_CAPTIONS_' + data_name + '.json'), 'r') as j:\n","            self.captions = json.load(j)\n","\n","\n","        self.transforms = transforms\n","\n","\n","    def __getitem__(self, i):\n","        img = torch.FloatTensor(self.imgs[i // self.captions_per_image] / 255.)\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        cap_len = torch.LongTensor([self.cap_lens[i]])\n","        caption = torch.LongTensor(self.captions[i])\n","\n","\n","\n","        if self.splits is 'TRAIN':\n","            return img, caption, caplen\n","        else:\n","            all_captions = torch.LongTensor(\n","                self.captions[((i // self.captions_per_image) * self.captions_per_image):(((i // self.captions_per_image) * self.captions_per_image) + self.captions_per_image)])\n","            return img, caption, cap_len, all_captions\n","\n","    def __len__(self):\n","        return self.dataset_size\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JtKLDVdzRHHy"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"MxHEuthsRJKn"},"source":["\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","class CNN(nn.Module):\n","\n","\n","    def __init__(self, encode_image_size=14):\n","        super(CNN, self).__init__()\n","        self.encode_image_size = encode_image_size\n","\n","        resnet50 = torchvision.models.resnet5050(pretrained=True)  \n","\n","        modules = list(resnet50.children())[:-2]\n","        self.resnet50 = nn.Sequential(*modules)\n","\n","        self.adaptive_pools = nn.AdaptiveAvgPool2d((encoded_image_size, encoded_image_size))\n","\n","        self.fine_tune()\n","\n","    def forward(self, images):\n","\n","        out = self.resnet50(images) \n","        out = self.adaptive_pools(out)  \n","        out = out.permute(0, 2, 3, 1)  \n","        return out\n","\n","    def fine_tune(self, fine_tune=True):\n","        for p in self.resnet50.parameters():\n","            p.requires_grad = False\n","        for c in list(self.resnet50.children())[5:]:\n","            for p in c.parameters():\n","                p.requires_grad = fine_tune\n","\n","\n","class Attention(nn.Module):\n","\n","\n","    def __init__(self, CNN_dim, decoder_dim, attention_dim):\n","\n","        super(Attention, self).__init__()\n","        self.CNN_att = nn.Linear(CNN_dim, attention_dim)  \n","        self.decoder_att = nn.Linear(decoder_dim, attention_dim) \n","        self.full_att = nn.Linear(attention_dim, 1)  \n","        self.relu = nn.ReLU()\n","        self.softmax = nn.Softmax(dim=1)  \n","\n","    def forward(self, CNN_out, decoder_hidden):\n","\n","        att1 = self.CNN_att(CNN_out)  \n","        att2 = self.decoder_att(decoder_hidden) \n","        att = self.full_att(self.relu(att1 + att2.unsqueeze(1))).squeeze(2) \n","        alpha = self.softmax(att)  \n","        attention_weighted_encoding = (CNN_out * alpha.unsqueeze(2)).sum(dim=1)  \n","\n","        return attention_weighted_encoding, alpha\n","\n","\n","class LSTMWithAttention(nn.Module):\n","\n","\n","    def __init__(self, attention_dim, embed_dim, decoder_dim, vocab_size, CNN_dim=2048, dropout=0.5):\n","        super(LSTMwithAttention, self).__init__()\n","\n","        self.CNN_dims = CNN_dim\n","        self.attention_dims = attention_dim\n","        self.embed_dims = embed_dim\n","        self.decoder_dims = decoder_dim\n","        self.vocab_sizes = vocab_size\n","        self.dropouts = dropout\n","\n","        self.attentions = Attention(CNN_dim, decoder_dim, attention_dim)  \n","\n","        self.embeddings = nn.Embedding(vocab_size, embed_dim)  \n","        self.dropouts = nn.Dropout(p=self.dropout)\n","        self.decode_steps = nn.LSTMCell(embed_dim + CNN_dim, decoder_dim, bias=True)  \n","        self.init_hs = nn.Linear(CNN_dim, decoder_dim)  \n","        self.init_cs = nn.Linear(CNN_dim, decoder_dim) \n","        self.f_betas = nn.Linear(decoder_dim, CNN_dim) \n","        self.sigmoids = nn.Sigmoid()\n","        self.fcs = nn.Linear(decoder_dim, vocab_size) \n","        self.init_weights()  \n","\n","    def init_weights(self):\n","\n","        self.embeddings.weight.data.uniform_(-0.1, 0.1)\n","        self.fcs.bias.data.fill_(0)\n","        self.fcs.weight.data.uniform_(-0.1, 0.1)\n","\n","    def load_pretrained_embeddings(self, embeddings):\n","        self.embeddings.weight = nn.Parameter(embeddings)\n","\n","    def fine_tune_embeddings(self, fine_tune=True):\n","        for p in self.embeddings.parameters():\n","            p.requires_grad = fine_tune\n","\n","    def init_hidden_state(self, CNN_out):\n","        mean_CNN_out = CNN_out.mean(dim=1)\n","        hs = self.init_h(mean_CNN_out)  \n","        cs = self.init_c(mean_CNN_out)\n","        return hs, cs\n","\n","    def forward(self, CNN_out, encoded_captions, caption_lengths):\n","        batch_size = CNN_out.size(0)\n","        CNN_dim = CNN_out.size(-1)\n","        vocab_size = self.vocab_size\n","\n","        CNN_out = CNN_out.view(batch_size, -1, CNN_dim)  \n","        num_pixels = CNN_out.size(1)\n","\n","        caption_lengths, sort_ind = caption_lengths.squeeze(1).sort(dim=0, descending=True)\n","        CNN_out = CNN_out[sort_ind]\n","        encoded_captions = encoded_captions[sort_ind]\n","\n","        embeddings = self.embeddings(encoded_captions)  \n","        h, c = self.init_hidden_state(CNN_out)  \n","        decode_lengths = (caption_lengths - 1).tolist()\n","\n","        predictions = torch.zeros(batch_size, max(decode_lengths), vocab_size).to(device)\n","        alphas = torch.zeros(batch_size, max(decode_lengths), num_pixels).to(device)\n","\n","        for t in range(max(decode_lengths)):\n","            batch_size_t = sum([l > t for l in decode_lengths])\n","            attention_weighted_encoding, alpha = self.attention(CNN_out[:batch_size_t],\n","                                                                h[:batch_size_t])\n","            gate = self.sigmoid(self.f_beta(h[:batch_size_t]))  \n","            attention_weighted_encoding = gate * attention_weighted_encoding\n","            h, c = self.decode_step(\n","                torch.cat([embeddings[:batch_size_t, t, :], attention_weighted_encoding], dim=1),\n","                (h[:batch_size_t], c[:batch_size_t]))  \n","            preds = self.fc(self.dropout(h))  \n","            predictions[:batch_size_t, t, :] = preds\n","            alphas[:batch_size_t, t, :] = alpha\n","\n","        return predictions, encoded_captions, decode_lengths, alphas, sort_ind\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FLvL0FiOLf-r"},"source":["\n","def train(train_loader, CNN, decoder, criterion, CNN_optimizer, decoder_optimizer, epoch):\n","\n","\n","    decoder.train()  \n","    CNN.train()\n","\n","    batch_time = AvgMtr()  \n","    data_time = AvgMtr()  \n","    losses = AvgMtr()  \n","    top5accs = AvgMtr()  \n","    start = time.time()\n","\n","    for i, (imgs, caps, cap_lens) in enumerate(train_loader):\n","        data_time.update(time.time() - start)\n","\n","        imgs = imgs.to(device)\n","        caps = caps.to(device)\n","        cap_lens = cap_lens.to(device)\n","\n","\n","        imgs = CNN(imgs)\n","        scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, cap_lens)\n","\n","\n","        targets = caps_sorted[:, 1:]\n","\n","        scores = pack_padded_sequence(scores, decode_lengths, batch_first=True)[0]\n","        targets = pack_padded_sequence(targets, decode_lengths, batch_first=True)[0]\n","\n","        loss = criterion(scores, targets)\n","\n","        loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n","\n","        decoder_optimizer.zero_grad()\n","        if CNN_optimizer is not None:\n","            CNN_optimizer.zero_grad()\n","        loss.backward()\n","\n","        if grad_clip is not None:\n","            clip_gradient(decoder_optimizer, grad_clip)\n","            if CNN_optimizer is not None:\n","                clip_gradient(CNN_optimizer, grad_clip)\n","\n","        decoder_optimizer.step()\n","        if CNN_optimizer is not None:\n","            CNN_optimizer.step()\n","\n","        top5 = accuracy(scores, targets, 5)\n","        losses.update(loss.item(), sum(decode_lengths))\n","        top5accs.update(top5, sum(decode_lengths))\n","        batch_time.update(time.time() - start)\n","\n","        start = time.time()\n","\n","   \n","        if i % print_freq == 0:\n","            print('Epoch: [{0}][{1}/{2}]\\t'\n","                  'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'Data Load Time {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","                  'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})'.format(epoch, i, len(train_loader),\n","                                                                          batch_time=batch_time,\n","                                                                          data_time=data_time, loss=losses,\n","                                                                          top5=top5accs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXqYeUlnLma-"},"source":["\n","def validate(val_loader, CNN, decoder, criterion):\n","\n","    decoder.eval()  \n","    if CNN is not None:\n","        CNN.eval()\n","\n","    batch_time = AvgMtr()\n","    losses = AvgMtr()\n","    top5accs = AvgMtr()\n","\n","    start = time.time()\n","\n","    references = list()  \n","    with torch.no_grad():\n","        # Batches\n","        for i, (imgs, caps, cap_lens, allcaps) in enumerate(val_loader):\n","\n","            imgs = imgs.to(device)\n","            caps = caps.to(device)\n","            cap_lens = cap_lens.to(device)\n","\n","            if CNN is not None:\n","                imgs = CNN(imgs)\n","            scores, caps_sorted, decode_lengths, alphas, sort_ind = decoder(imgs, caps, cap_lens)\n","\n","            targets = caps_sorted[:, 1:]\n","\n","            scores_copy = scores.clone()\n","            scores = pack_padded_sequence(scores, decode_lengths, batch_first=True)[0]\n","            targets = pack_padded_sequence(targets, decode_lengths, batch_first=True)[0]\n","\n","            loss = criterion(scores, targets)\n","\n","            loss += alpha_c * ((1. - alphas.sum(dim=1)) ** 2).mean()\n","\n","            losses.update(loss.item(), sum(decode_lengths))\n","            top5 = accuracy(scores, targets, 5)\n","            top5accs.update(top5, sum(decode_lengths))\n","            batch_time.update(time.time() - start)\n","\n","            start = time.time()\n","\n","            if i % print_freq == 0:\n","                print('Validation: [{0}/{1}]\\t'\n","                      'Batch Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","                      'Top-5 Accuracy {top5.val:.3f} ({top5.avg:.3f})\\t'.format(i, len(val_loader), batch_time=batch_time,\n","                                                                                loss=losses, top5=top5accs))\n","\n","            allcaps = allcaps[sort_ind]  \n","            for j in range(allcaps.shape[0]):\n","                img_caps = allcaps[j].tolist()\n","                img_captions = list(\n","                    map(lambda c: [w for w in c if w not in {word_map['<start>'], word_map['<pad>']}],\n","                        img_caps))  \n","                references.append(img_captions)\n","\n","\n","            _, preds = torch.max(scores_copy, dim=2)\n","            preds = preds.tolist()\n","            temp_preds = list()\n","            for j, p in enumerate(preds):\n","                temp_preds.append(preds[j][:decode_lengths[j]])  # remove pads\n","            preds = temp_preds\n","            hypotheses.extend(preds)\n","\n","            assert len(references) == len(hypotheses)\n","\n","        bleu4 = corpus_bleu(references, hypotheses)\n","\n","        print(\n","            '\\n * LOSS - {loss.avg:.3f}, TOP-5 ACCURACY - {top5.avg:.3f}, BLEU-4 - {bleu}\\n'.format(\n","                loss=losses,\n","                top5=top5accs,\n","                bleu=bleu4))\n","\n","    return bleu4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lLAHy9YJ3s6M"},"source":["\n","\n","# Data parameters\n","data_folder = '/content/drive/MyDrive/CV/out/' \n","data_name = 'flickr8k_5_cap_per_img_5_min_word_freq'  \n","\n","# Model parameters\n","emb_dim = 512  \n","attention_dim = 512  \n","decoder_dim = 512  \n","dropout = 0.5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n","cudnn.benchmark = True \n","\n","# Training parameters\n","start_epoch = 0\n","epochs = 10 \n","epochs_since_improvement = 0  \n","batch_size = 32\n","workers = 1  \n","CNN_lr = 1e-4  \n","decoder_lr = 4e-4  \n","grad_clip = 5. \n","alpha_c = 1.  \n","best_bleu4 = 0.  \n","print_freq = 100\n","fine_tune_CNN = False  \n","checkpoint = None \n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ZusZmuxLSol","executionInfo":{"status":"ok","timestamp":1636822986548,"user_tz":-330,"elapsed":2794829,"user":{"displayName":"17PD35 - SRUTHI S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13321935041235545449"}},"outputId":"4e426feb-111d-4ec4-e966-c39ee1896eee"},"source":["def main():\n","\n","\n","    global best_bleu4, epochs_since_improvement, checkpoint, start_epoch, fine_tune_CNN, data_name, word_map\n","\n","    word_map_file = os.path.join(data_folder, 'WORDMAP_' + data_name + '.json')\n","    with open(word_map_file, 'r') as j:\n","        word_map = json.load(j)\n","\n","\n","    if checkpoint is None:\n","        decoder = LSTMwithAttention(attention_dim=attention_dim,\n","                                       embed_dim=emb_dim,\n","                                       decoder_dim=decoder_dim,\n","                                       vocab_size=len(word_map),\n","                                       dropout=dropout)\n","        decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()),\n","                                             lr=decoder_lr)\n","        CNN = CNN()\n","        CNN.fine_tune(fine_tune_CNN)\n","        CNN_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, CNN.parameters()),\n","                                             lr=CNN_lr) if fine_tune_CNN else None\n","\n","    else:\n","        checkpoint = torch.load(checkpoint)\n","        start_epoch = checkpoint['epoch'] + 1\n","        epochs_since_improvement = checkpoint['epochs_since_improvement']\n","        best_bleu4 = checkpoint['bleu-4']\n","        decoder = checkpoint['decoder']\n","        decoder_optimizer = checkpoint['decoder_optimizer']\n","        CNN = checkpoint['CNN']\n","        CNN_optimizer = checkpoint['CNN_optimizer']\n","        if fine_tune_CNN is True and CNN_optimizer is None:\n","            CNN.fine_tune(fine_tune_CNN)\n","            CNN_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, CNN.parameters()),\n","                                                 lr=CNN_lr)\n","\n","    decoder = decoder.to(device)\n","    CNN = CNN.to(device)\n","\n","    criterion = nn.CrossEntropyLoss().to(device)\n","\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","    train_loader = torch.utils.data.DataLoader(\n","        Captions_Dataset(data_folder, data_name, 'TRAIN', transform=transforms.Compose([normalize])),\n","        batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n","    val_loader = torch.utils.data.DataLoader(\n","        Captions_Dataset(data_folder, data_name, 'VAL', transform=transforms.Compose([normalize])),\n","        batch_size=batch_size, shuffle=True, num_workers=workers, pin_memory=True)\n","\n","    for epoch in tqdm(range(start_epoch, epochs), desc = \"Epochs\"):\n","\n","        if epochs_since_improvement == 20:\n","            break\n","        if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n","            adjust_learning_rate(decoder_optimizer, 0.8)\n","            if fine_tune_CNN:\n","                adjust_learning_rate(CNN_optimizer, 0.8)\n","\n","        train(train_loader=train_loader,\n","              CNN=CNN,\n","              decoder=decoder,\n","              criterion=criterion,\n","              CNN_optimizer=CNN_optimizer,\n","              decoder_optimizer=decoder_optimizer,\n","              epoch=epoch)\n","\n","        recent_bleu4 = validate(val_loader=val_loader,\n","                                CNN=CNN,\n","                                decoder=decoder,\n","                                criterion=criterion)\n","\n","        is_best = recent_bleu4 > best_bleu4\n","        best_bleu4 = max(recent_bleu4, best_bleu4)\n","        if not is_best:\n","            epochs_since_improvement += 1\n","            print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n","        else:\n","            epochs_since_improvement = 0\n","\n","\n","\n","if __name__ == '__main__':\n","    main()\n"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEpochs:   0%|          | 0/10 [00:00<?, ?it/s]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [0][0/938]\tBatch Time 1.099 (1.099)\tData Load Time 0.212 (0.212)\tLoss 8.8387 (8.8387)\tTop-5 Accuracy 0.000 (0.000)\n","Epoch: [0][100/938]\tBatch Time 0.735 (0.774)\tData Load Time 0.000 (0.002)\tLoss 5.7041 (6.1299)\tTop-5 Accuracy 40.230 (35.036)\n","Epoch: [0][200/938]\tBatch Time 0.755 (0.774)\tData Load Time 0.000 (0.001)\tLoss 4.9754 (5.7669)\tTop-5 Accuracy 50.000 (39.685)\n","Epoch: [0][300/938]\tBatch Time 0.751 (0.772)\tData Load Time 0.000 (0.001)\tLoss 4.7979 (5.5155)\tTop-5 Accuracy 53.911 (43.424)\n","Epoch: [0][400/938]\tBatch Time 0.721 (0.772)\tData Load Time 0.000 (0.001)\tLoss 4.7721 (5.3472)\tTop-5 Accuracy 52.959 (45.823)\n","Epoch: [0][500/938]\tBatch Time 0.787 (0.773)\tData Load Time 0.001 (0.001)\tLoss 4.5057 (5.2194)\tTop-5 Accuracy 57.368 (47.621)\n","Epoch: [0][600/938]\tBatch Time 0.814 (0.773)\tData Load Time 0.003 (0.001)\tLoss 4.5344 (5.1082)\tTop-5 Accuracy 58.929 (49.224)\n","Epoch: [0][700/938]\tBatch Time 0.764 (0.774)\tData Load Time 0.000 (0.001)\tLoss 4.2406 (5.0170)\tTop-5 Accuracy 64.000 (50.472)\n","Epoch: [0][800/938]\tBatch Time 0.760 (0.775)\tData Load Time 0.000 (0.001)\tLoss 4.4646 (4.9434)\tTop-5 Accuracy 57.609 (51.445)\n","Epoch: [0][900/938]\tBatch Time 0.808 (0.775)\tData Load Time 0.000 (0.001)\tLoss 4.4628 (4.8772)\tTop-5 Accuracy 56.186 (52.335)\n","Validation: [0/157]\tBatch Time 0.766 (0.766)\tLoss 4.0231 (4.0231)\tTop-5 Accuracy 63.265 (63.265)\t\n","Validation: [100/157]\tBatch Time 0.587 (0.590)\tLoss 4.3550 (4.2221)\tTop-5 Accuracy 57.576 (60.941)\t\n","\n"," * LOSS - 4.219, TOP-5 ACCURACY - 61.065, BLEU-4 - 0.12108739119879222\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEpochs:  10%|█         | 1/10 [13:42<2:03:25, 822.86s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/938]\tBatch Time 1.060 (1.060)\tData Load Time 0.247 (0.247)\tLoss 4.3736 (4.3736)\tTop-5 Accuracy 57.027 (57.027)\n","Epoch: [1][100/938]\tBatch Time 0.759 (0.774)\tData Load Time 0.000 (0.003)\tLoss 4.2424 (4.2176)\tTop-5 Accuracy 61.478 (60.864)\n","Epoch: [1][200/938]\tBatch Time 0.793 (0.775)\tData Load Time 0.000 (0.002)\tLoss 3.8129 (4.1845)\tTop-5 Accuracy 67.662 (61.369)\n","Epoch: [1][300/938]\tBatch Time 0.772 (0.774)\tData Load Time 0.000 (0.001)\tLoss 4.1959 (4.1760)\tTop-5 Accuracy 61.602 (61.435)\n","Epoch: [1][400/938]\tBatch Time 0.778 (0.775)\tData Load Time 0.000 (0.001)\tLoss 4.0903 (4.1616)\tTop-5 Accuracy 64.925 (61.591)\n","Epoch: [1][500/938]\tBatch Time 0.730 (0.774)\tData Load Time 0.000 (0.001)\tLoss 4.0507 (4.1454)\tTop-5 Accuracy 62.286 (61.762)\n","Epoch: [1][600/938]\tBatch Time 0.771 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.8274 (4.1342)\tTop-5 Accuracy 65.957 (61.975)\n","Epoch: [1][700/938]\tBatch Time 0.791 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.8930 (4.1210)\tTop-5 Accuracy 65.995 (62.176)\n","Epoch: [1][800/938]\tBatch Time 0.781 (0.774)\tData Load Time 0.000 (0.001)\tLoss 4.0193 (4.1082)\tTop-5 Accuracy 63.171 (62.355)\n","Epoch: [1][900/938]\tBatch Time 0.788 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.7007 (4.0949)\tTop-5 Accuracy 67.070 (62.500)\n","Validation: [0/157]\tBatch Time 0.735 (0.735)\tLoss 3.8797 (3.8797)\tTop-5 Accuracy 64.208 (64.208)\t\n","Validation: [100/157]\tBatch Time 0.579 (0.585)\tLoss 3.8797 (3.9443)\tTop-5 Accuracy 68.132 (64.789)\t\n","\n"," * LOSS - 3.939, TOP-5 ACCURACY - 64.885, BLEU-4 - 0.14292622876746053\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEpochs:  20%|██        | 2/10 [27:23<1:49:33, 821.69s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [2][0/938]\tBatch Time 1.066 (1.066)\tData Load Time 0.187 (0.187)\tLoss 3.8447 (3.8447)\tTop-5 Accuracy 66.253 (66.253)\n","Epoch: [2][100/938]\tBatch Time 0.766 (0.779)\tData Load Time 0.000 (0.002)\tLoss 3.6172 (3.8684)\tTop-5 Accuracy 69.974 (65.227)\n","Epoch: [2][200/938]\tBatch Time 0.774 (0.776)\tData Load Time 0.000 (0.001)\tLoss 4.3711 (3.8596)\tTop-5 Accuracy 58.649 (65.516)\n","Epoch: [2][300/938]\tBatch Time 0.784 (0.775)\tData Load Time 0.000 (0.001)\tLoss 3.8770 (3.8549)\tTop-5 Accuracy 60.741 (65.558)\n","Epoch: [2][400/938]\tBatch Time 0.775 (0.775)\tData Load Time 0.000 (0.001)\tLoss 3.7714 (3.8510)\tTop-5 Accuracy 68.490 (65.659)\n","Epoch: [2][500/938]\tBatch Time 0.773 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.8423 (3.8468)\tTop-5 Accuracy 66.220 (65.759)\n","Epoch: [2][600/938]\tBatch Time 0.823 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.7524 (3.8394)\tTop-5 Accuracy 68.828 (65.898)\n","Epoch: [2][700/938]\tBatch Time 0.756 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.8953 (3.8354)\tTop-5 Accuracy 66.576 (65.990)\n","Epoch: [2][800/938]\tBatch Time 0.737 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.5064 (3.8309)\tTop-5 Accuracy 70.536 (66.037)\n","Epoch: [2][900/938]\tBatch Time 0.798 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.9158 (3.8269)\tTop-5 Accuracy 63.427 (66.076)\n","Validation: [0/157]\tBatch Time 0.728 (0.728)\tLoss 3.6833 (3.6833)\tTop-5 Accuracy 68.466 (68.466)\t\n","Validation: [100/157]\tBatch Time 0.601 (0.587)\tLoss 3.7840 (3.8049)\tTop-5 Accuracy 66.748 (66.495)\t\n","\n"," * LOSS - 3.813, TOP-5 ACCURACY - 66.402, BLEU-4 - 0.14623803146733674\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEpochs:  30%|███       | 3/10 [41:04<1:35:48, 821.25s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [3][0/938]\tBatch Time 1.057 (1.057)\tData Load Time 0.186 (0.186)\tLoss 3.6786 (3.6786)\tTop-5 Accuracy 66.223 (66.223)\n","Epoch: [3][100/938]\tBatch Time 0.791 (0.777)\tData Load Time 0.000 (0.002)\tLoss 3.5566 (3.6460)\tTop-5 Accuracy 69.877 (68.512)\n","Epoch: [3][200/938]\tBatch Time 0.802 (0.775)\tData Load Time 0.001 (0.001)\tLoss 3.7763 (3.6570)\tTop-5 Accuracy 68.408 (68.259)\n","Epoch: [3][300/938]\tBatch Time 0.767 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.3867 (3.6623)\tTop-5 Accuracy 71.802 (68.088)\n","Epoch: [3][400/938]\tBatch Time 0.774 (0.773)\tData Load Time 0.002 (0.001)\tLoss 3.5198 (3.6578)\tTop-5 Accuracy 68.449 (68.186)\n","Epoch: [3][500/938]\tBatch Time 0.752 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.4854 (3.6603)\tTop-5 Accuracy 68.286 (68.159)\n","Epoch: [3][600/938]\tBatch Time 0.730 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.6074 (3.6634)\tTop-5 Accuracy 68.935 (68.148)\n","Epoch: [3][700/938]\tBatch Time 0.767 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.5650 (3.6630)\tTop-5 Accuracy 70.876 (68.159)\n","Epoch: [3][800/938]\tBatch Time 0.759 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.5826 (3.6580)\tTop-5 Accuracy 71.060 (68.267)\n","Epoch: [3][900/938]\tBatch Time 0.758 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.6639 (3.6531)\tTop-5 Accuracy 69.429 (68.379)\n","Validation: [0/157]\tBatch Time 0.727 (0.727)\tLoss 3.5549 (3.5549)\tTop-5 Accuracy 70.190 (70.190)\t\n","Validation: [100/157]\tBatch Time 0.572 (0.587)\tLoss 3.5800 (3.7173)\tTop-5 Accuracy 70.225 (67.917)\t\n","\n"," * LOSS - 3.728, TOP-5 ACCURACY - 67.695, BLEU-4 - 0.15296582060571323\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEpochs:  40%|████      | 4/10 [54:45<1:22:06, 821.01s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [4][0/938]\tBatch Time 1.053 (1.053)\tData Load Time 0.256 (0.256)\tLoss 3.4832 (3.4832)\tTop-5 Accuracy 72.434 (72.434)\n","Epoch: [4][100/938]\tBatch Time 0.798 (0.780)\tData Load Time 0.000 (0.003)\tLoss 3.2866 (3.5110)\tTop-5 Accuracy 75.062 (70.396)\n","Epoch: [4][200/938]\tBatch Time 0.777 (0.779)\tData Load Time 0.000 (0.002)\tLoss 3.4480 (3.5103)\tTop-5 Accuracy 69.171 (70.397)\n","Epoch: [4][300/938]\tBatch Time 0.767 (0.779)\tData Load Time 0.000 (0.001)\tLoss 3.3328 (3.5110)\tTop-5 Accuracy 72.576 (70.392)\n","Epoch: [4][400/938]\tBatch Time 0.822 (0.778)\tData Load Time 0.000 (0.001)\tLoss 3.7398 (3.5203)\tTop-5 Accuracy 66.826 (70.238)\n","Epoch: [4][500/938]\tBatch Time 0.765 (0.778)\tData Load Time 0.000 (0.001)\tLoss 3.4282 (3.5203)\tTop-5 Accuracy 70.000 (70.264)\n","Epoch: [4][600/938]\tBatch Time 0.791 (0.777)\tData Load Time 0.000 (0.001)\tLoss 3.6524 (3.5167)\tTop-5 Accuracy 67.308 (70.361)\n","Epoch: [4][700/938]\tBatch Time 0.783 (0.777)\tData Load Time 0.000 (0.001)\tLoss 3.5951 (3.5179)\tTop-5 Accuracy 68.653 (70.328)\n","Epoch: [4][800/938]\tBatch Time 0.739 (0.777)\tData Load Time 0.000 (0.001)\tLoss 3.1365 (3.5149)\tTop-5 Accuracy 78.324 (70.374)\n","Epoch: [4][900/938]\tBatch Time 0.782 (0.777)\tData Load Time 0.001 (0.001)\tLoss 3.5890 (3.5142)\tTop-5 Accuracy 69.251 (70.368)\n","Validation: [0/157]\tBatch Time 0.746 (0.746)\tLoss 3.6775 (3.6775)\tTop-5 Accuracy 67.778 (67.778)\t\n","Validation: [100/157]\tBatch Time 0.602 (0.589)\tLoss 3.8780 (3.6854)\tTop-5 Accuracy 65.625 (68.377)\t\n","\n"," * LOSS - 3.684, TOP-5 ACCURACY - 68.339, BLEU-4 - 0.1541437191725238\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEpochs:  50%|█████     | 5/10 [1:08:29<1:08:30, 822.09s/it]"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [5][0/938]\tBatch Time 1.165 (1.165)\tData Load Time 0.253 (0.253)\tLoss 3.2936 (3.2936)\tTop-5 Accuracy 74.046 (74.046)\n","Epoch: [5][100/938]\tBatch Time 0.738 (0.779)\tData Load Time 0.001 (0.003)\tLoss 3.3916 (3.3968)\tTop-5 Accuracy 69.565 (72.163)\n","Epoch: [5][200/938]\tBatch Time 0.791 (0.776)\tData Load Time 0.000 (0.002)\tLoss 3.4732 (3.3998)\tTop-5 Accuracy 69.975 (72.117)\n","Epoch: [5][300/938]\tBatch Time 0.791 (0.775)\tData Load Time 0.000 (0.001)\tLoss 3.3504 (3.4066)\tTop-5 Accuracy 71.638 (71.998)\n","Epoch: [5][400/938]\tBatch Time 0.791 (0.775)\tData Load Time 0.000 (0.001)\tLoss 3.5559 (3.4037)\tTop-5 Accuracy 69.797 (72.048)\n","Epoch: [5][500/938]\tBatch Time 0.767 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.4585 (3.4025)\tTop-5 Accuracy 71.391 (72.089)\n","Epoch: [5][600/938]\tBatch Time 0.719 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.3505 (3.4060)\tTop-5 Accuracy 72.393 (72.017)\n","Epoch: [5][700/938]\tBatch Time 0.761 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.3175 (3.4040)\tTop-5 Accuracy 73.829 (72.034)\n","Epoch: [5][800/938]\tBatch Time 0.804 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.2625 (3.4051)\tTop-5 Accuracy 72.886 (72.035)\n","Epoch: [5][900/938]\tBatch Time 0.785 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.2184 (3.4036)\tTop-5 Accuracy 73.924 (72.052)\n","Validation: [0/157]\tBatch Time 0.752 (0.752)\tLoss 3.7855 (3.7855)\tTop-5 Accuracy 67.609 (67.609)\t\n","Validation: [100/157]\tBatch Time 0.582 (0.588)\tLoss 3.7832 (3.6425)\tTop-5 Accuracy 70.725 (68.924)\t\n","\n"," * LOSS - 3.652, TOP-5 ACCURACY - 68.849, BLEU-4 - 0.15859725496206775\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\rEpochs:  60%|██████    | 6/10 [1:22:09<54:46, 821.62s/it]  "]},{"output_type":"stream","name":"stdout","text":["Epoch: [6][0/938]\tBatch Time 1.092 (1.092)\tData Load Time 0.189 (0.189)\tLoss 3.1084 (3.1084)\tTop-5 Accuracy 75.556 (75.556)\n","Epoch: [6][100/938]\tBatch Time 0.767 (0.775)\tData Load Time 0.000 (0.002)\tLoss 3.4841 (3.2899)\tTop-5 Accuracy 69.048 (73.795)\n","Epoch: [6][200/938]\tBatch Time 0.793 (0.776)\tData Load Time 0.002 (0.001)\tLoss 3.5419 (3.2849)\tTop-5 Accuracy 69.330 (73.840)\n","Epoch: [6][300/938]\tBatch Time 0.774 (0.776)\tData Load Time 0.000 (0.001)\tLoss 3.2572 (3.2915)\tTop-5 Accuracy 75.067 (73.667)\n","Epoch: [6][400/938]\tBatch Time 0.756 (0.775)\tData Load Time 0.000 (0.001)\tLoss 3.1360 (3.2907)\tTop-5 Accuracy 72.652 (73.692)\n","Epoch: [6][500/938]\tBatch Time 0.739 (0.775)\tData Load Time 0.000 (0.001)\tLoss 3.4010 (3.3011)\tTop-5 Accuracy 71.225 (73.534)\n","Epoch: [6][600/938]\tBatch Time 0.779 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.5580 (3.2998)\tTop-5 Accuracy 68.146 (73.585)\n","Epoch: [6][700/938]\tBatch Time 0.768 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.1819 (3.3018)\tTop-5 Accuracy 74.271 (73.547)\n","Epoch: [6][800/938]\tBatch Time 0.783 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.3771 (3.3032)\tTop-5 Accuracy 72.751 (73.530)\n","Epoch: [6][900/938]\tBatch Time 0.775 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.2258 (3.3050)\tTop-5 Accuracy 76.786 (73.492)\n","Validation: [0/157]\tBatch Time 0.729 (0.729)\tLoss 3.3191 (3.3191)\tTop-5 Accuracy 72.589 (72.589)\t\n","Validation: [100/157]\tBatch Time 0.587 (0.585)\tLoss 3.5437 (3.6416)\tTop-5 Accuracy 71.684 (68.996)\t\n","\n"," * LOSS - 3.641, TOP-5 ACCURACY - 69.097, BLEU-4 - 0.1592288822563543\n","\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs:  70%|███████   | 7/10 [1:35:50<41:03, 821.25s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: [7][0/938]\tBatch Time 1.142 (1.142)\tData Load Time 0.232 (0.232)\tLoss 3.0755 (3.0755)\tTop-5 Accuracy 75.641 (75.641)\n","Epoch: [7][100/938]\tBatch Time 0.793 (0.783)\tData Load Time 0.000 (0.003)\tLoss 3.2048 (3.1910)\tTop-5 Accuracy 74.169 (75.065)\n","Epoch: [7][200/938]\tBatch Time 0.770 (0.777)\tData Load Time 0.000 (0.002)\tLoss 3.4207 (3.1917)\tTop-5 Accuracy 71.129 (75.056)\n","Epoch: [7][300/938]\tBatch Time 0.773 (0.776)\tData Load Time 0.000 (0.001)\tLoss 3.3171 (3.2002)\tTop-5 Accuracy 72.533 (74.996)\n","Epoch: [7][400/938]\tBatch Time 0.745 (0.776)\tData Load Time 0.000 (0.001)\tLoss 3.2309 (3.2042)\tTop-5 Accuracy 76.438 (75.001)\n","Epoch: [7][500/938]\tBatch Time 0.756 (0.776)\tData Load Time 0.000 (0.001)\tLoss 3.2991 (3.2069)\tTop-5 Accuracy 73.529 (74.984)\n","Epoch: [7][600/938]\tBatch Time 0.738 (0.775)\tData Load Time 0.000 (0.001)\tLoss 3.0519 (3.2113)\tTop-5 Accuracy 76.705 (74.878)\n","Epoch: [7][700/938]\tBatch Time 0.748 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.2480 (3.2126)\tTop-5 Accuracy 76.177 (74.872)\n","Epoch: [7][800/938]\tBatch Time 0.788 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.3830 (3.2157)\tTop-5 Accuracy 69.149 (74.794)\n","Epoch: [7][900/938]\tBatch Time 0.740 (0.774)\tData Load Time 0.002 (0.001)\tLoss 3.2476 (3.2176)\tTop-5 Accuracy 73.414 (74.779)\n","Validation: [0/157]\tBatch Time 0.724 (0.724)\tLoss 3.4545 (3.4545)\tTop-5 Accuracy 71.850 (71.850)\t\n","Validation: [100/157]\tBatch Time 0.579 (0.586)\tLoss 3.7778 (3.6383)\tTop-5 Accuracy 66.667 (69.328)\t\n","\n"," * LOSS - 3.630, TOP-5 ACCURACY - 69.411, BLEU-4 - 0.16193480575714686\n","\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs:  80%|████████  | 8/10 [1:49:31<27:22, 821.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: [8][0/938]\tBatch Time 1.103 (1.103)\tData Load Time 0.190 (0.190)\tLoss 3.1718 (3.1718)\tTop-5 Accuracy 73.629 (73.629)\n","Epoch: [8][100/938]\tBatch Time 0.754 (0.775)\tData Load Time 0.000 (0.002)\tLoss 3.2382 (3.0813)\tTop-5 Accuracy 74.731 (76.981)\n","Epoch: [8][200/938]\tBatch Time 0.755 (0.772)\tData Load Time 0.000 (0.001)\tLoss 3.1947 (3.1080)\tTop-5 Accuracy 76.045 (76.567)\n","Epoch: [8][300/938]\tBatch Time 0.751 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.2882 (3.1152)\tTop-5 Accuracy 73.596 (76.442)\n","Epoch: [8][400/938]\tBatch Time 0.820 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.0245 (3.1214)\tTop-5 Accuracy 76.812 (76.300)\n","Epoch: [8][500/938]\tBatch Time 0.766 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.1636 (3.1247)\tTop-5 Accuracy 74.400 (76.231)\n","Epoch: [8][600/938]\tBatch Time 0.771 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.0861 (3.1312)\tTop-5 Accuracy 80.851 (76.145)\n","Epoch: [8][700/938]\tBatch Time 0.754 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.2985 (3.1363)\tTop-5 Accuracy 75.698 (76.077)\n","Epoch: [8][800/938]\tBatch Time 0.783 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.1700 (3.1370)\tTop-5 Accuracy 76.081 (76.063)\n","Epoch: [8][900/938]\tBatch Time 0.769 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.0353 (3.1373)\tTop-5 Accuracy 76.093 (76.068)\n","Validation: [0/157]\tBatch Time 0.734 (0.734)\tLoss 3.6328 (3.6328)\tTop-5 Accuracy 67.684 (67.684)\t\n","Validation: [100/157]\tBatch Time 0.593 (0.586)\tLoss 3.6484 (3.6065)\tTop-5 Accuracy 66.408 (69.756)\t\n","\n"," * LOSS - 3.625, TOP-5 ACCURACY - 69.494, BLEU-4 - 0.1624639763450037\n","\n"]},{"output_type":"stream","name":"stderr","text":["\rEpochs:  90%|█████████ | 9/10 [2:03:12<13:41, 821.18s/it]"]},{"output_type":"stream","name":"stdout","text":["Epoch: [9][0/938]\tBatch Time 1.125 (1.125)\tData Load Time 0.234 (0.234)\tLoss 3.0588 (3.0588)\tTop-5 Accuracy 76.338 (76.338)\n","Epoch: [9][100/938]\tBatch Time 0.779 (0.775)\tData Load Time 0.000 (0.003)\tLoss 3.0365 (3.0246)\tTop-5 Accuracy 77.719 (77.860)\n","Epoch: [9][200/938]\tBatch Time 0.786 (0.772)\tData Load Time 0.000 (0.002)\tLoss 3.0576 (3.0254)\tTop-5 Accuracy 78.646 (77.805)\n","Epoch: [9][300/938]\tBatch Time 0.757 (0.771)\tData Load Time 0.000 (0.001)\tLoss 3.0208 (3.0387)\tTop-5 Accuracy 76.554 (77.609)\n","Epoch: [9][400/938]\tBatch Time 0.779 (0.772)\tData Load Time 0.000 (0.001)\tLoss 3.1705 (3.0414)\tTop-5 Accuracy 76.517 (77.517)\n","Epoch: [9][500/938]\tBatch Time 0.777 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.0602 (3.0491)\tTop-5 Accuracy 77.979 (77.408)\n","Epoch: [9][600/938]\tBatch Time 0.767 (0.773)\tData Load Time 0.000 (0.001)\tLoss 3.0656 (3.0535)\tTop-5 Accuracy 77.454 (77.337)\n","Epoch: [9][700/938]\tBatch Time 0.779 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.1444 (3.0585)\tTop-5 Accuracy 77.151 (77.286)\n","Epoch: [9][800/938]\tBatch Time 0.763 (0.774)\tData Load Time 0.000 (0.001)\tLoss 3.0869 (3.0562)\tTop-5 Accuracy 77.249 (77.322)\n","Epoch: [9][900/938]\tBatch Time 0.798 (0.775)\tData Load Time 0.000 (0.001)\tLoss 2.8791 (3.0583)\tTop-5 Accuracy 80.702 (77.288)\n","Validation: [0/157]\tBatch Time 0.715 (0.715)\tLoss 3.7165 (3.7165)\tTop-5 Accuracy 68.156 (68.156)\t\n","Validation: [100/157]\tBatch Time 0.577 (0.587)\tLoss 3.8065 (3.6220)\tTop-5 Accuracy 69.086 (69.686)\t\n","\n"," * LOSS - 3.638, TOP-5 ACCURACY - 69.444, BLEU-4 - 0.15794535778587318\n","\n","\n","Epochs since last improvement: 1\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epochs: 100%|██████████| 10/10 [2:16:53<00:00, 821.35s/it]\n"]}]}]}